{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amandazhang/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, CuDNNLSTM, RepeatVector, TimeDistributed, ConvLSTM2D\n",
    "import pylidc as pl\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dims = (256, 256, 1)\n",
    "num_slices = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(TimeDistributed(UNet(image_dims, start_ch=32, batchnorm=True), input_shape=(num_slices,) + image_dims))\n",
    "model.add(ConvLSTM2D(filters=40, kernel_size=(3, 3), \n",
    "                     input_shape=(num_slices, 256, 256, 1),\n",
    "                     padding='same', return_sequences=True))\n",
    "#model.add(TimeDistributed(Flatten()))\n",
    "#model.add(RepeatVector(num_slices))\n",
    "#model.add(CuDNNLSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scans = pl.query(pl.Scan)\n",
    "n = scans.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (20,256,256,1) into shape (1,20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a864045029e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (20,256,256,1) into shape (1,20)"
     ]
    }
   ],
   "source": [
    "np.array(get_data(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_annotated_slices(ann):\n",
    "    zs = ann.bbox()[-1]\n",
    "    return zs.start, zs.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(i):\n",
    "    scan = scans[i]\n",
    "    images = scan.load_all_dicom_images(verbose=False)\n",
    "    n = len(images)\n",
    "    X = np.array([[resize(im.pixel_array, (256, 256), mode='constant') for im in images]])\n",
    "    nodule_zs = set.union(*(set(range(*get_annotated_slices(ann))) for ann in scan.annotations))\n",
    "    y = np.array([[i in nodule_zs for i in range(n)]])\n",
    "    start = int((n - num_slices) / 2)\n",
    "    X = X[:, start:start + num_slices]\n",
    "    y = y[:, start:start + num_slices]\n",
    "    return np.expand_dims(X, axis=-1), np.expand_dims(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datagen():\n",
    "    i = np.random.randint(n)\n",
    "    yield get_data(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 20, 256, 256, 40)  59200     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 20, 256, 256, 1)   41        \n",
      "=================================================================\n",
      "Total params: 59,241\n",
      "Trainable params: 59,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 256, 256, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected time_distributed_3 to have 5 dimensions, but got array with shape (1, 20, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7c57e5f3ce57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected time_distributed_3 to have 5 dimensions, but got array with shape (1, 20, 1)"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(n):\n",
    "        data = get_data(i)\n",
    "        print(data[0].shape)\n",
    "        model.fit(data[0], data[1].astype('int32'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "helo = get_data(i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]],\n",
       "\n",
       "\n",
       "        [[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]],\n",
       "\n",
       "\n",
       "        [[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]],\n",
       "\n",
       "\n",
       "        [[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]],\n",
       "\n",
       "\n",
       "        [[[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]],\n",
       "\n",
       "         [[-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          ...,\n",
       "          [-0.06248569],\n",
       "          [-0.06248569],\n",
       "          [-0.06248569]]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = datagen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'close',\n",
       " 'gi_code',\n",
       " 'gi_frame',\n",
       " 'gi_running',\n",
       " 'gi_yieldfrom',\n",
       " 'send',\n",
       " 'throw']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = get_data(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[20,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_1/conv2d_15/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_1/concatenate_2/concat, conv2d_15/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/acc/Mean_1/_1661 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9422_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'time_distributed_1/conv2d_15/convolution', defined at:\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-71e608002942>\", line 2, in <module>\n    model.add(TimeDistributed(UNet(image_dims, start_ch=32, batchnorm=True), input_shape=(num_slices,) + image_dims))\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 211, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 952, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[20,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_1/conv2d_15/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_1/concatenate_2/concat, conv2d_15/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/acc/Mean_1/_1661 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9422_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_1/conv2d_15/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_1/concatenate_2/concat, conv2d_15/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/acc/Mean_1/_1661 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9422_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1622e5700d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[20,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_1/conv2d_15/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_1/concatenate_2/concat, conv2d_15/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/acc/Mean_1/_1661 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9422_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'time_distributed_1/conv2d_15/convolution', defined at:\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-71e608002942>\", line 2, in <module>\n    model.add(TimeDistributed(UNet(image_dims, start_ch=32, batchnorm=True), input_shape=(num_slices,) + image_dims))\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 211, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 952, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\lhe\\Anaconda3\\envs\\py3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[20,128,64,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: time_distributed_1/conv2d_15/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](time_distributed_1/concatenate_2/concat, conv2d_15/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/acc/Mean_1/_1661 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_9422_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "-200000.0\n",
      "9999999999.0\n"
     ]
    }
   ],
   "source": [
    "delt = 1.\n",
    "delxp = 1.\n",
    "delx = 100000.\n",
    "c = 299792458.\n",
    "\n",
    "print(delt**2 + delxp**2/c**2)\n",
    "print(-2*delx*delt)\n",
    "print(delx**2 - delxp**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999443730591\n"
     ]
    }
   ],
   "source": [
    "v = 99999.\n",
    "v = 101000.\n",
    "\n",
    "print( (delt - (v*delx / c**2))/(np.sqrt(1-v**2/c**2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1126278031637625e-07"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v**2/c**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
